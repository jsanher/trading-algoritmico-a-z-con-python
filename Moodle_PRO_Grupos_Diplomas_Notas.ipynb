{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1JD5uevDBxJDv_14urbgPJodM24dRIvv9",
      "authorship_tag": "ABX9TyPwp67j2h4d1im8ekrIGbMK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsanher/trading-algoritmico-a-z-con-python/blob/main/Moodle_PRO_Grupos_Diplomas_Notas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7ch5ohBQ5MZ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import csv\n",
        "import datetime\n",
        "\n",
        "def AgruparAlumnos(file1):\n",
        "\n",
        "  # endpoint de la API\n",
        "  endpoint = \"https://formacion.nodofarma.es/moodle/assignGroup\"\n",
        "\n",
        "  # datos en formato JSON a enviar en la llamada PUT\n",
        "  data = {\n",
        "      \"courseLegacyID\":\"260015\",\n",
        "      \"grouptype\":\"C\"\n",
        "  }\n",
        "\n",
        "  # obtener la fecha actual\n",
        "  now = datetime.datetime.now()\n",
        "  # Formatear la fecha actual para incluir los segundos\n",
        "  date_string = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "  # crear el nombre del archivo de log con la fecha actual\n",
        "  log_file = \"log_{}.txt\".format(date_string)\n",
        "\n",
        "  # abrir el archivo CSV y leer las filas\n",
        "  with open(file1, 'r') as file:\n",
        "      reader = csv.reader(file)\n",
        "      # abrir el archivo de log\n",
        "      with open(log_file, \"w\") as log:\n",
        "          # iterar sobre las filas del CSV\n",
        "          for row in reader:\n",
        "              # obtener el userLegacyID de la fila\n",
        "              userLegacyID = row[0]\n",
        "              # agregar el userLegacyID al diccionario de datos JSON\n",
        "              data[\"userLegacyID\"] = userLegacyID\n",
        "              # realizar la llamada PUT\n",
        "              response = requests.put(endpoint, json=data)\n",
        "              # obtener el status code y descripcion de la respuesta\n",
        "              status_code = response.status_code\n",
        "              status_text = response.reason\n",
        "              # escribir la respuesta en el archivo de log\n",
        "              log.write(\"Llamada a {} con userLegacyID {} - Status: {} - {}\\n\".format(endpoint, userLegacyID, status_code, status_text))\n",
        "              print(\"Llamada a {} con userLegacyID {} - Status: {} - {}\".format(endpoint, userLegacyID, status_code, status_text))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AgruparAlumnos(\"Libro3.csv\")"
      ],
      "metadata": {
        "id": "IJM6V7uZOjWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# getScore\n"
      ],
      "metadata": {
        "id": "sk-XnnZiaHJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import csv\n",
        "import logging\n",
        "import json\n",
        "\n",
        "logging.basicConfig(filename='get_scores.log', level=logging.INFO)\n",
        "\n",
        "def get_scores(course_legacy_id, output_file):\n",
        "    # get quiz id\n",
        "    quiz_url = f\"https://formacion.nodofarma.es/moodle/listQuizzes?courseLegacyID={course_legacy_id}\"\n",
        "    quiz_response = requests.get(quiz_url)\n",
        "    quiz_data = quiz_response.json()\n",
        "    quiz_id = quiz_data['quizzes']\n",
        "    # get user data\n",
        "    user_url = f\"https://formacion.nodofarma.es/moodle/listCourseUsers?courseLegacyID={course_legacy_id}\"\n",
        "    user_response = requests.get(user_url)\n",
        "    user_data = user_response.json()\n",
        "    listausuarios = user_data['users']\n",
        "\n",
        "    print(listausuarios)\n",
        "\n",
        "    # write to output file\n",
        "    with open(output_file, 'w', newline='') as f_output:\n",
        "        writer = csv.writer(f_output)\n",
        "        # write header row\n",
        "        writer.writerow(['user_legacy_id', 'url', 'response'])\n",
        "        for element in listausuarios:\n",
        "            user_legacy_id = element\n",
        "            url = f\"https://formacion.nodofarma.es/moodle/getScore?quizID={quiz_id}&userLegacyID={user_legacy_id}\"\n",
        "            response = requests.get(url)\n",
        "            data = response.json()\n",
        "            writer.writerow([user_legacy_id, url, data])\n",
        "            logging.info(f\"URL: {url}, Response: {data}\")\n"
      ],
      "metadata": {
        "id": "NtQzASYcZoUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_scores(217, \"/content/salida2.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi2NIryifwFf",
        "outputId": "59c84e80-6218-4bd5-8fed-2c5df74482e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[102581, 76123, 57122, 132067, 137054, 42124, 82082, 128053, 125358, 122379, 20773, 36588, 55104, 149827, 75605, 114693, 43877, 112826, 23124, 100142, 119012, 41617, 51984, 122463, 35973, 48301, 50680, 79803, 86809, 129887, 134521, 135245, 141890, 145002, 7046, 35942, 41070, 41996, 45034, 51433, 56530, 57327, 76020, 100258, 102577, 110273, 127760, 16544, 31618, 39944, 101973, 148515, 1198, 12931, 37754, 46716, 56853, 86124, 122957, 143472, 24116, 29743, 38102, 38161, 39017, 75561, 100187, 111006, 6965, 13193, 10444, 44966, 45239, 56114, 75232, 81775, 100375, 100481, 115214, 120352, 135707, 155422, 23300, 46208, 55116, 123136, 130074, 135693, 151656, 54970, 900281, 85252, 85575, 100738, 107261, 56659, 50351, 101251, 110243, 19665, 39055, 51098, 54056, 81624, 85784, 102725, 107404, 110423, 128149, 147559, 44684, 76247, 106637, 106990, 117372, 133289, 145598, 16356, 36365, 37036, 37431, 81000, 102531, 124963, 140202, 7351, 54313, 82927, 103080, 34176, 109890, 119844, 135276, 136949, 43101, 48320, 83652, 110693, 112223, 122203, 33415, 40647, 83749, 113328, 110266, 40018, 36808, 113871, 129734, 142573, 122354, 56989, 50110, 50120, 148640, 102897, 102912, 52099, 110539, 109193, 139771, 47271, 54936, 109117, 50884, 260006, 75394, 135660, 131875]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def remove_error_rows(file_path):\n",
        "    # Abrir el archivo CSV original\n",
        "    with open(file_path, \"r\") as csv_file:\n",
        "        # Leer el archivo CSV original\n",
        "        csv_reader = csv.reader(csv_file)\n",
        "        \n",
        "        # Crear una lista para almacenar las líneas que no contienen \"error\" en la columna \"response\"\n",
        "        clean_rows = []\n",
        "        \n",
        "        # Recorrer cada línea del archivo CSV original\n",
        "        for row in csv_reader:\n",
        "            # Si la columna \"response\" no contiene \"error\"\n",
        "            if \"Error\" not in row[2]:\n",
        "                # Añadir la línea a la lista limpia\n",
        "                clean_rows.append(row)\n",
        "    \n",
        "    # Escribir las líneas limpias en un nuevo archivo CSV\n",
        "    with open(\"clean_\"+file_path, \"w\", newline='') as clean_file:\n",
        "        csv_writer = csv.writer(clean_file)\n",
        "        csv_writer.writerows(clean_rows)\n",
        "    print(f\"Archivo limpio generado con el nombre: clean_{file_path}\")\n"
      ],
      "metadata": {
        "id": "Hgeu0w7jBbMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_error_rows(\"salida2.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4Iqqw-oBjFx",
        "outputId": "02bab439-1a0c-4c85-9d1d-84e927f4ba92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo limpio generado con el nombre: clean_salida2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def remove_duplicates(file1, file2):\n",
        "    # Abrir el primer archivo CSV\n",
        "    with open(file1, \"r\") as csv_file1:\n",
        "        csv_reader1 = csv.reader(csv_file1)\n",
        "        # Guardar la primera columna del primer archivo CSV en una lista\n",
        "        first_column1 = [row[0] for row in csv_reader1]\n",
        "    # Abrir el segundo archivo CSV\n",
        "    with open(file2, \"r\") as csv_file2:\n",
        "        csv_reader2 = csv.reader(csv_file2)\n",
        "        # Crear una lista para almacenar las líneas únicas\n",
        "        unique_rows = []\n",
        "        # Recorrer cada línea del segundo archivo CSV\n",
        "        for row in csv_reader2:\n",
        "            # Si el campo de la primera columna no existe en el campo de la primera columna del primer archivo CSV\n",
        "            if row[0] not in first_column1:\n",
        "                # Añadir la línea a la lista de líneas únicas\n",
        "                unique_rows.append(row)\n",
        "\n",
        "    # Escribir las líneas únicas en un nuevo archivo CSV\n",
        "    with open(\"unique_rows.csv\", \"w\", newline='') as unique_file:\n",
        "        csv_writer = csv.writer(unique_file)\n",
        "        csv_writer.writerows(unique_rows)\n",
        "    print(f\"Archivo con las líneas únicas generado con el nombre: unique_rows.csv\")\n"
      ],
      "metadata": {
        "id": "erjs_JSYLiZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_duplicates(\"/content/Libro2.csv\",\"/content/Libro3.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mxJUKMfLyC2",
        "outputId": "8b24831f-2e51-419e-dac6-6030371fd971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo con las líneas únicas generado con el nombre: unique_rows.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import requests\n",
        "\n",
        "url = \"https://formacion.nodofarma.es/moodle/setCertificate\"\n",
        "headers = {'Content-Type': 'application/json;charset=UTF-8'}\n",
        "\n",
        "with open('/content/cuerpo4.csv', newline='') as csvfile:\n",
        "    data = csv.reader(csvfile)\n",
        "    next(data) # skip the header row\n",
        "    for row in data:\n",
        "        userLegacyID = row[0]\n",
        "        courseName = row[2]\n",
        "        urlDiploma = row[3]\n",
        "        order = row[4]\n",
        "        courseLegacyID = row[1]\n",
        "\n",
        "        payload = {\n",
        "            \"userLegacyID\": userLegacyID,\n",
        "            \"courseName\": courseName,\n",
        "            \"url\": urlDiploma,\n",
        "            \"order\": order,\n",
        "            \"courseLegacyID\": courseLegacyID\n",
        "        }\n",
        "\n",
        "        print(payload)\n",
        "        response = requests.put(url, json=payload, headers=headers)\n",
        "        print(response.status_code, response.reason) # check if the request was successful\n"
      ],
      "metadata": {
        "id": "vqDD0QQofNfT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}